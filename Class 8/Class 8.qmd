---
title: "Class 8"
author: Vivian Chau (A16913056)
format: pdf
---

>**Take-home**: Generally we always want to set `scale=TRUE` when we do this type of analysis to avoid our analysis being dominated by individual variables with the largest variance just due to their unit of measurement. 

##FNA breast cancer data

Load the data into R. 
```{r}
wisc.df<-read.csv("WisconsinCancer.csv",row.names=1)
head(wisc.df)
```

> Q1. How many observations are in this dataset?

```{r}
nrow(wisc.df)
```

> Q2. How many of the observations have a malignant diagnosis?

```{r}
sum(wisc.df$diagnosis == "M")

```

The `table()` function is super useful here:

```{r}
table(wisc.df$diagnosis)
```

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
colnames(wisc.df)
```

A useful function for this is `grep()`

```{r}
length(grep("_mean", colnames(wisc.df)))
```

Before we go any further we need to exclude the diagnosis column from any future analysis - this tells us whether a sample to cancer or non-cancer.

```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
```

```{r}
wisc.data<-wisc.df[,-1]

```

Lets see if we can cluster the `wisc.data` to find some structure in the data set. 

```{r}
hc<-hclust(dist(wisc.data))
plot(hc)
```

## Principal Component Analysis (PCA)
```{r}
wisc.pr<-prcomp(wisc.data,scale = T)
summary(wisc.pr)
```

>Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
0.4427 of the original variance is captured by the first principal components.

>Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
3 principal components are required to describe at least 70% of the original variance in the data. 

>Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
9 principal components are required to describe at least 90% of the original variance in the data. 


```{r}
biplot(wisc.pr)
```
>Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?
This plot has a lot of dots and lines that make the plot difficult to understand.

This biplot sucks! We need to build our own PCA score plot of PC1 vs PC2 
```{r}
head(wisc.pr$x)

```

Plot of PC1 vs PC2 the first two columns
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col = diagnosis)
```

>Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?
These plots are similar but there are more overlaps between the malignant and benign diagnosis.

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col = diagnosis)
```

## Calculating the variance of each component

```{r}
pr.var<-wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <-pr.var/sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
        names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

## Communicating PCA results

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?
concave.points_mean is -0.26085376

```{r}
wisc.pr$rotation[,1]
```

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?
5 principal components

## Hierarchical clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist, method="complete")
```

## Results of hierarchical clustering

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?
At height=19, the clustering model has 4 clusters.

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

```{r}
unique(cutree(wisc.hclust,h=19))
```

Selecting number of clusters

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=6)
table(wisc.hclust.clusters, diagnosis)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?
Dividing the clusters into k=4 will result in a better cluster vs diagnoses match. 

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=3)
table(wisc.hclust.clusters, diagnosis)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=4)
table(wisc.hclust.clusters, diagnosis)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=5)
table(wisc.hclust.clusters, diagnosis)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=7)
table(wisc.hclust.clusters, diagnosis)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=8)
table(wisc.hclust.clusters, diagnosis)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust,k=9)
table(wisc.hclust.clusters, diagnosis)
```

## Using different methods

> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.
The "complete" method gives my favorite results for the same data.dist dataset because it provides all the data for clustering and adjustments can be made after to separate the clusters.

## K-means clustering and comparing results
> Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?
K-means separates the two diagnoses better.

```{r}
wisc.km <- kmeans(scale(wisc.data), centers= 2, nstart= 20)
table(wisc.hclust.clusters, wisc.km$cluster)
```

## Clustering on PCA results 

```{r}
wisc.pr.hclust<-hclust(dist(wisc.pr$x[,1:7]),method="ward.D2")
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

> Q15. How well does the newly created model with four clusters separate out the two diagnoses?

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)

# Compare to actual diagnoses 
table(wisc.pr.hclust.clusters, diagnosis)
```

> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
table(wisc.km$cluster, diagnosis)
```
```{r}
table(wisc.hclust.clusters, diagnosis)
```

## Sensitivity/Specificity 
> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

Sensitivity 

```{r}
#wisc.km$cluster
175/(175+14)
```
```{r}
#wisc.hclust.clusters
86/(86+12)
```

Specificity 

```{r}
#wisc.km$cluster
343/(343+37)
```
```{r}
#wisc.hclust.clusters
331/(331+39)
```

The wisc.km$cluster had a better specificity and sensitivity. 

## Clustering in PC space
```{r}
hc<-hclust(dist(wisc.pr$x[,1:2]), method="ward.D2")

plot(hc)
abline(h=70, col="red")
```

Cluster membership vector

```{r}
grps<-cutree(hc, h=70)
table(grps)
```

```{r}
table(diagnosis)
```

Cross-table to see how my clustering groups correspond to the expert diagnosis vector of M and B values

```{r}
table(grps,diagnosis)
```

Positive => cancer M 
Negative => non-cancer B

True = cluster/group 1 
False = group 2 

True Positive = 177 
False Positive = 18 
True Negative = 339 
False Negative = 35 

## Predictions 

We can use our PCA results (wisc.pr) to make predictions on new unseen data. 

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
```


```{r}
plot(wisc.pr$x[,1:2],col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?
We should prioritize patients who are truly ill and have tested positive for the condition. 